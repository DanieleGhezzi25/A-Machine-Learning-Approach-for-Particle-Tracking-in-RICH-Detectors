{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872a3ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training su dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import sys \n",
    "\n",
    "sys.path.append(r'/user/gr1/delphi/dghezzi/UNet')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from UNet import UNet, TwoPatchDataset, train_unet_with_patches\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Training su dispositivo: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c3c862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos weight CENTRO (416x416):  92.1424 ± 0.3570  (n=1000)\n",
      "Pos weight CORNICE (resto):   1035.3766 ± 6.7930  (n=1000)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "directory = '/user/gr1/delphi/dghezzi/UNet/UNet_dataset/4000_1000_160_180_npy_double_input'\n",
    "val_labels_dir = os.path.join(directory, \"labels\", \"val\")\n",
    "\n",
    "pos_weights_center = []\n",
    "pos_weights_frame = []\n",
    "\n",
    "for label_file in os.listdir(val_labels_dir):\n",
    "    if label_file.endswith('.npy'):\n",
    "        heatmap = np.load(os.path.join(val_labels_dir, label_file))\n",
    "        h, w = heatmap.shape\n",
    "        assert h == 800 and w == 800, \"Le heatmap devono essere 800x800\"\n",
    "\n",
    "        # --- REGIONI ---\n",
    "        # Centro 416x416\n",
    "        start_y = (h - 416) // 2\n",
    "        start_x = (w - 416) // 2\n",
    "        end_y = start_y + 416\n",
    "        end_x = start_x + 416\n",
    "\n",
    "        center = heatmap[start_y:end_y, start_x:end_x]\n",
    "        frame_mask = np.ones_like(heatmap, dtype=bool)\n",
    "        frame_mask[start_y:end_y, start_x:end_x] = False\n",
    "        frame = heatmap[frame_mask]\n",
    "\n",
    "        # --- POS WEIGHT CENTRO ---\n",
    "        pos_mass_center = np.sum(center)\n",
    "        neg_mass_center = center.size - pos_mass_center\n",
    "        pos_weight_center = neg_mass_center / (pos_mass_center + 1e-6)\n",
    "        pos_weights_center.append(pos_weight_center)\n",
    "\n",
    "        # --- POS WEIGHT CORNICE ---\n",
    "        pos_mass_frame = np.sum(frame)\n",
    "        neg_mass_frame = frame.size - pos_mass_frame\n",
    "        pos_weight_frame = neg_mass_frame / (pos_mass_frame + 1e-6)\n",
    "        pos_weights_frame.append(pos_weight_frame)\n",
    "\n",
    "# --- STATISTICHE ---\n",
    "pos_weights_center = np.array(pos_weights_center)\n",
    "pos_weights_frame = np.array(pos_weights_frame)\n",
    "\n",
    "mean_center = np.mean(pos_weights_center)\n",
    "err_center = np.std(pos_weights_center) / np.sqrt(len(pos_weights_center))\n",
    "\n",
    "mean_frame = np.mean(pos_weights_frame)\n",
    "err_frame = np.std(pos_weights_frame) / np.sqrt(len(pos_weights_frame))\n",
    "\n",
    "print(f\"Pos weight CENTRO (416x416):  {mean_center:.4f} ± {err_center:.4f}  (n={len(pos_weights_center)})\")\n",
    "print(f\"Pos weight CORNICE (resto):   {mean_frame:.4f} ± {err_frame:.4f}  (n={len(pos_weights_frame)})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74db31a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]: 100%|██████████| 1406/1406 [38:45<00:00,  1.65s/it]\n",
      "Epoch 1/100 [Val]: 100%|██████████| 157/157 [05:04<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.558121 | Val Loss: 1.582175\n",
      "F1 @2px: 0.0069 | F1 @4px: 0.0166 | F1 @6px: 0.0205 | Weighted F1: 0.0158\n",
      " ==> Nuovo modello salvato (val loss e F1 migliorati)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [Train]: 100%|██████████| 1406/1406 [39:28<00:00,  1.68s/it]\n",
      "Epoch 2/100 [Val]: 100%|██████████| 157/157 [05:14<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.475975 | Val Loss: 1.587978\n",
      "F1 @2px: 0.0071 | F1 @4px: 0.0166 | F1 @6px: 0.0197 | Weighted F1: 0.0156\n",
      " ==> Nessun miglioramento. patience: 1/7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [Train]: 100%|██████████| 1406/1406 [40:17<00:00,  1.72s/it]\n",
      "Epoch 3/100 [Val]: 100%|██████████| 157/157 [05:16<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.452881 | Val Loss: 1.765162\n",
      "F1 @2px: 0.0066 | F1 @4px: 0.0153 | F1 @6px: 0.0185 | Weighted F1: 0.0146\n",
      " ==> Nessun miglioramento. patience: 2/7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [Train]:  48%|████▊     | 671/1406 [19:01<21:00,  1.71s/it]Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/user/gr1/delphi/dghezzi/.venv/lib64/python3.9/site-packages/torch/utils/data/_utils/pin_memory.py\", line 51, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/user/gr1/delphi/dghezzi/.venv/lib64/python3.9/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib64/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/user/gr1/delphi/dghezzi/.venv/lib64/python3.9/site-packages/torch/multiprocessing/reductions.py\", line 307, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib64/python3.9/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib64/python3.9/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib64/python3.9/multiprocessing/connection.py\", line 506, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/usr/lib64/python3.9/multiprocessing/connection.py\", line 634, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Epoch 4/100 [Train]:  48%|████▊     | 671/1406 [19:01<20:50,  1.70s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m\n\u001b[1;32m     26\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m     27\u001b[0m     val_dataset,\n\u001b[1;32m     28\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Avvia il training\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrain_unet_with_patches\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbinary_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.97\u001b[39;49m\n\u001b[1;32m     45\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completato e cache GPU svuotata.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/UNet/UNet.py:1073\u001b[0m, in \u001b[0;36mtrain_unet_with_patches\u001b[0;34m(model, train_loader, val_loader, num_epochs, lr, device, patience, binary_threshold)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         loss \u001b[38;5;241m=\u001b[39m bce_loss(outputs, labels)\n\u001b[1;32m   1072\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m-> 1073\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m   1076\u001b[0m loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m patch_weights[patch] \u001b[38;5;241m*\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:370\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:289\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    288\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    290\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Istanzia modello\n",
    "model = UNet(in_channels=1, out_channels=1)  # canale singolo per heatmap\n",
    "\n",
    "# Percorsi dati (assicurati che ci siano cartelle separate per train e val)\n",
    "directory = '/user/gr1/delphi/dghezzi/UNet/UNet_dataset/22500_2500_160_180_npy'\n",
    "train_image_dir = f'{directory}/images/train'\n",
    "train_label_dir = f'{directory}/labels/train'\n",
    "val_image_dir = f'{directory}/images/val'\n",
    "val_label_dir = f'{directory}/labels/val'\n",
    "\n",
    "# Dataset e DataLoader\n",
    "train_dataset = TwoPatchDataset(image_dir=train_image_dir, label_dir=train_label_dir, transform=None)\n",
    "val_dataset = TwoPatchDataset(image_dir=val_image_dir, label_dir=val_label_dir, transform=None)\n",
    "\n",
    "batch = 16\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=4,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Avvia il training\n",
    "train_unet_with_patches(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=100,\n",
    "    lr=1e-3,\n",
    "    device=device,\n",
    "    patience=7,\n",
    "    binary_threshold=0.97\n",
    ")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Training completato e cache GPU svuotata.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
