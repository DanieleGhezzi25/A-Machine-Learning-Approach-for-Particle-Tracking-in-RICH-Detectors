{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3faca04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b0309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training su dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]: 100%|██████████| 500/500 [05:54<00:00,  1.41it/s]\n",
      "Epoch 1/100 [Val]: 100%|██████████| 125/125 [00:49<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.873140 | Val Loss: 0.842160\n",
      "Val BCE Loss: 0.708993 | Val Dice Loss: 0.975328\n",
      "F1 (thresholds = 2px): 0.0044 | F1 (thresholds = 4px): 0.0123 | F1 (thresholds = 6px): 0.0178\n",
      "Weighted F1: 0.5 x 0.0044 + 0.35 x 0.0123 + 0.15 x 0.0178 = 0.0092\n",
      "[GPU] alloc: 484.9 MB | max: 18575.9 MB\n",
      " ==> Nuovo modello salvato (val loss e F1 migliorati)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [Train]: 100%|██████████| 500/500 [05:59<00:00,  1.39it/s]\n",
      "Epoch 2/100 [Val]: 100%|██████████| 125/125 [00:49<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.835232 | Val Loss: 0.837309\n",
      "Val BCE Loss: 0.704860 | Val Dice Loss: 0.969757\n",
      "F1 (thresholds = 2px): 0.0041 | F1 (thresholds = 4px): 0.0116 | F1 (thresholds = 6px): 0.0175\n",
      "Weighted F1: 0.5 x 0.0041 + 0.35 x 0.0116 + 0.15 x 0.0175 = 0.0088\n",
      "[GPU] alloc: 485.7 MB | max: 18575.9 MB\n",
      " ==> Nuovo modello salvato (val loss migliorata)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [Train]: 100%|██████████| 500/500 [05:59<00:00,  1.39it/s]\n",
      "Epoch 3/100 [Val]: 100%|██████████| 125/125 [00:49<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.829501 | Val Loss: 0.830826\n",
      "Val BCE Loss: 0.690824 | Val Dice Loss: 0.970827\n",
      "F1 (thresholds = 2px): 0.0045 | F1 (thresholds = 4px): 0.0122 | F1 (thresholds = 6px): 0.0174\n",
      "Weighted F1: 0.5 x 0.0045 + 0.35 x 0.0122 + 0.15 x 0.0174 = 0.0091\n",
      "[GPU] alloc: 485.5 MB | max: 18575.9 MB\n",
      " ==> Nuovo modello salvato (val loss migliorata)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [Train]: 100%|██████████| 500/500 [05:59<00:00,  1.39it/s]\n",
      "Epoch 4/100 [Val]: 100%|██████████| 125/125 [00:49<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.825349 | Val Loss: 0.828786\n",
      "Val BCE Loss: 0.684975 | Val Dice Loss: 0.972598\n",
      "F1 (thresholds = 2px): 0.0046 | F1 (thresholds = 4px): 0.0122 | F1 (thresholds = 6px): 0.0176\n",
      "Weighted F1: 0.5 x 0.0046 + 0.35 x 0.0122 + 0.15 x 0.0176 = 0.0092\n",
      "[GPU] alloc: 484.9 MB | max: 18575.9 MB\n",
      " ==> Nuovo modello salvato (val loss e F1 migliorati)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [Train]: 100%|██████████| 500/500 [05:55<00:00,  1.40it/s]\n",
      "Epoch 5/100 [Val]: 100%|██████████| 125/125 [00:49<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.821402 | Val Loss: 0.829933\n",
      "Val BCE Loss: 0.687355 | Val Dice Loss: 0.972511\n",
      "F1 (thresholds = 2px): 0.0048 | F1 (thresholds = 4px): 0.0117 | F1 (thresholds = 6px): 0.0167\n",
      "Weighted F1: 0.5 x 0.0048 + 0.35 x 0.0117 + 0.15 x 0.0167 = 0.0090\n",
      "[GPU] alloc: 485.7 MB | max: 18575.9 MB\n",
      " ==> Nessun miglioramento. patience: 1/7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [Train]: 100%|██████████| 500/500 [05:56<00:00,  1.40it/s]\n",
      "Epoch 6/100 [Val]: 100%|██████████| 125/125 [00:48<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.817090 | Val Loss: 0.829053\n",
      "Val BCE Loss: 0.685728 | Val Dice Loss: 0.972378\n",
      "F1 (thresholds = 2px): 0.0048 | F1 (thresholds = 4px): 0.0114 | F1 (thresholds = 6px): 0.0163\n",
      "Weighted F1: 0.5 x 0.0048 + 0.35 x 0.0114 + 0.15 x 0.0163 = 0.0089\n",
      "[GPU] alloc: 485.5 MB | max: 18575.9 MB\n",
      " ==> Nessun miglioramento. patience: 2/7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [Train]: 100%|██████████| 500/500 [05:56<00:00,  1.40it/s]\n",
      "Epoch 7/100 [Val]: 100%|██████████| 125/125 [00:49<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.811551 | Val Loss: 0.842670\n",
      "Val BCE Loss: 0.715627 | Val Dice Loss: 0.969712\n",
      "F1 (thresholds = 2px): 0.0051 | F1 (thresholds = 4px): 0.0130 | F1 (thresholds = 6px): 0.0189\n",
      "Weighted F1: 0.5 x 0.0051 + 0.35 x 0.0130 + 0.15 x 0.0189 = 0.0099\n",
      "[GPU] alloc: 484.9 MB | max: 18575.9 MB\n",
      " ==> Nuovo modello salvato (F1 migliorata)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [Train]: 100%|██████████| 500/500 [05:56<00:00,  1.40it/s]\n",
      "Epoch 8/100 [Val]: 100%|██████████| 125/125 [00:49<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.804321 | Val Loss: 0.840820\n",
      "Val BCE Loss: 0.711409 | Val Dice Loss: 0.970231\n",
      "F1 (thresholds = 2px): 0.0043 | F1 (thresholds = 4px): 0.0118 | F1 (thresholds = 6px): 0.0166\n",
      "Weighted F1: 0.5 x 0.0043 + 0.35 x 0.0118 + 0.15 x 0.0166 = 0.0088\n",
      "[GPU] alloc: 485.7 MB | max: 18575.9 MB\n",
      " ==> Nessun miglioramento. patience: 1/7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [Train]:   8%|▊         | 41/500 [00:29<05:29,  1.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m get_dataloaders(data_dir\u001b[38;5;241m=\u001b[39mdatapath, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m800\u001b[39m,\u001b[38;5;241m800\u001b[39m))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Avvia il training\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mtrain_unet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completato e cache GPU svuotata.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/UNet/UNet.py:458\u001b[0m, in \u001b[0;36mtrain_unet\u001b[0;34m(model, train_loader, val_loader, num_epochs, lr, device, patience, binary_threshold)\u001b[0m\n\u001b[1;32m    455\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m    456\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m bce_loss(outputs, labels) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m dice_loss(outputs, labels)\n\u001b[0;32m--> 458\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m    460\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib64/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from UNet import UNet, get_dataloaders, train_unet, UNetWithAttention\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Training su dispositivo: {device}\")\n",
    "\n",
    "# Istanzia modello\n",
    "model = UNetWithAttention(in_channels=1, out_channels=1)  # o 3 se RGB\n",
    "\n",
    "# Carica i dataloader (adatta il path)\n",
    "datapath = '/user/gr1/delphi/dghezzi/UNet/UNet_dataset/4000_1000_160_180_npy'\n",
    "train_loader, val_loader = get_dataloaders(data_dir=datapath, batch_size=8, image_size=(800,800))\n",
    "\n",
    "# Avvia il training\n",
    "train_unet(model, train_loader, val_loader, num_epochs=100, lr=1e-3, device=device, patience=7)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(\"Training completato e cache GPU svuotata.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
